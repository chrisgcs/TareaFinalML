{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SoEZrWE99--S"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"Train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e0GEFN88A63U"
   },
   "outputs": [],
   "source": [
    "import re, time\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "\n",
    "def base_word(word):\n",
    "    wordlemmatizer = WordNetLemmatizer()\n",
    "    return wordlemmatizer.lemmatize(word) \n",
    "def word_extractor(text_input):\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text_input) #substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ base_word(word.lower()) for word in word_tokenize(text) ]\n",
    "    \n",
    "    for word in wordtokens:\n",
    "        if word not in commonwords: #and len(word)>3:  #delete stopwords and emogis\n",
    "            words+=\" \"+word\n",
    "    if len(words) == 0:\n",
    "        print(text_input)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sKk-PG6CBUi1"
   },
   "outputs": [],
   "source": [
    "train_lemm = []\n",
    "test_lemm = []\n",
    "for tweet in df_train.tweet_content:\n",
    "    train_lemm.append(word_extractor(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "woguuAi-BXWg"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer= CountVectorizer(ngram_range=(1, 1), binary=False)\n",
    "vectorizer.fit(train_lemm)\n",
    "\n",
    "features_train = vectorizer.transform(train_lemm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kCRWmozkBRQu"
   },
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "W9w4PpYRCWo3",
    "outputId": "6340aa8a-77c0-4642-8faf-53d6c278f05e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_train, df_train.harassment, test_size=0.25, random_state=27,shuffle = True)\n",
    "\n",
    "sm = SMOTE(random_state=27, ratio=1.0)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#smote = RandomForestClassifier(n_estimators=10).fit(X_train, y_train)\n",
    "smote = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "smote.fit(X_train, y_train)\n",
    "\n",
    "smote_pred = smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "66JWJGbwCZx4",
    "outputId": "f91299eb-7c81-4bcb-eb5a-bc66539fea21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 138,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HLnX6CF7C3XS",
    "outputId": "ac21aa5d-9ed5-416b-ded7-d7e1e7675186"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8401122019635343"
      ]
     },
     "execution_count": 139,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "N7slBhWfFjvs",
    "outputId": "e2ecb1b7-30c5-4df9-bcfb-8388cfbb383b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4411764705882353"
      ]
     },
     "execution_count": 140,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test,smote_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3JmOkbcXG4fW"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"Test_input.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJMQX13XIgVX"
   },
   "outputs": [],
   "source": [
    "test_lemm = []\n",
    "for tweet in df_test.tweet_content:\n",
    "    test_lemm.append(word_extractor(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pc5GPQ03Izel"
   },
   "outputs": [],
   "source": [
    "features_test = vectorizer.transform(test_lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4U5Erb9_I9yV"
   },
   "outputs": [],
   "source": [
    "smote_pred_test = smote.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FVSfZQFYJGtl",
    "outputId": "e8df1789-36b3-41f1-e0a4-6d9c26307f5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 145,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L3Y7sal8JIMh"
   },
   "outputs": [],
   "source": [
    "submission = open('submission.csv','w')\n",
    "submission.write(\"id,harassment\\n\")\n",
    "for i in range(len(df_test.id)):\n",
    "    submission.write(str(df_test.id[i])+\",\"+str(smote_pred_test[i])+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LXj2YhFXBWKg"
   },
   "source": [
    "#OVERSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "tl7vd0XDJrVc",
    "outputId": "15621e72-6d79-42c6-b312-362668b67fe8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3874\n",
       "0    3874\n",
       "Name: harassment, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate input features and target\n",
    "y = df_train.harassment\n",
    "X = df_train.tweet_content\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27, shuffle = True)\n",
    "\n",
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# separate minority and majority classes\n",
    "not_H = X[X.harassment==0]\n",
    "H = X[X.harassment==1]\n",
    "\n",
    "# upsample minority\n",
    "H_upsampled = resample(H,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_H), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([not_H, H_upsampled])\n",
    "\n",
    "# check new class counts\n",
    "upsampled.harassment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8kQsBu3aKMt0"
   },
   "outputs": [],
   "source": [
    "y_train = upsampled.harassment\n",
    "X_train = upsampled.drop('harassment', axis=1)\n",
    "\n",
    "train_lemm = []\n",
    "for tweet in X_train.tweet_content:\n",
    "    train_lemm.append(word_extractor(tweet))\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer= CountVectorizer(ngram_range=(1, 1), binary=False)\n",
    "vectorizer.fit(train_lemm)\n",
    "\n",
    "features_train = vectorizer.transform(train_lemm)\n",
    "\n",
    "\n",
    "upsampled = LogisticRegression(solver='liblinear').fit(features_train, y_train)\n",
    "\n",
    "#upsampled_pred = upsampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9SFr6vsVDjaN"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"Test_input.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yFHNV_SYDlX_"
   },
   "outputs": [],
   "source": [
    "test_lemm = []\n",
    "for tweet in df_test.tweet_content:\n",
    "    test_lemm.append(word_extractor(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ukJzQ7_-DpSS"
   },
   "outputs": [],
   "source": [
    "features_test = vectorizer.transform(test_lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m5qo5tr2Dr1Y"
   },
   "outputs": [],
   "source": [
    "smote_pred_test = upsampled.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_qfdaLq0DuHx"
   },
   "outputs": [],
   "source": [
    "smote_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4c3r4MHBDwCq"
   },
   "outputs": [],
   "source": [
    "submission = open('submission.csv','w')\n",
    "submission.write(\"id,harassment\\n\")\n",
    "for i in range(len(df_test.id)):\n",
    "    submission.write(str(df_test.id[i])+\",\"+str(smote_pred_test[i])+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C4WCmCyxBnWw"
   },
   "source": [
    "#UNDERSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "J0p3oF6Fa0cq",
    "outputId": "9172add1-efb8-4fbe-f2f0-f98f4f0d351a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    403\n",
       "0    403\n",
       "Name: harassment, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate input features and target\n",
    "y = df_train.harassment\n",
    "X = df_train.tweet_content\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27, shuffle = True)\n",
    "\n",
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# separate minority and majority classes\n",
    "not_H = X[X.harassment==0]\n",
    "H = X[X.harassment==1]\n",
    "\n",
    "# upsample minority\n",
    "not_H_downsampled = resample(not_H,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(H), # match minority n\n",
    "                                random_state = 27) # reproducible results\n",
    "\n",
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([not_H_downsampled, H])\n",
    "\n",
    "# check new class counts\n",
    "downsampled.harassment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LmX7Q8mBa1PE"
   },
   "outputs": [],
   "source": [
    "y_train = downsampled.harassment\n",
    "X_train = downsampled.drop('harassment', axis=1)\n",
    "\n",
    "train_lemm = []\n",
    "for tweet in X_train.tweet_content:\n",
    "    train_lemm.append(word_extractor(tweet))\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer= CountVectorizer(ngram_range=(1, 1), binary=False)\n",
    "vectorizer.fit(train_lemm)\n",
    "\n",
    "features_train = vectorizer.transform(train_lemm)\n",
    "\n",
    "\n",
    "upsampled = LogisticRegression(solver='liblinear').fit(features_train, y_train)\n",
    "\n",
    "#upsampled_pred = upsampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJ6srk_Uvu0H"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"Test_input.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NA3Z7VoPDzAv"
   },
   "outputs": [],
   "source": [
    "test_lemm = []\n",
    "for tweet in df_test.tweet_content:\n",
    "    test_lemm.append(word_extractor(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "myQZgWIhD02o"
   },
   "outputs": [],
   "source": [
    "features_test = vectorizer.transform(test_lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f2OhIfzRD2uP"
   },
   "outputs": [],
   "source": [
    "smote_pred_test = upsampled.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YdpFYoQvD4aN"
   },
   "outputs": [],
   "source": [
    "smote_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YgLbtcUmD5_O"
   },
   "outputs": [],
   "source": [
    "submission = open('submission.csv','w')\n",
    "submission.write(\"id,harassment\\n\")\n",
    "for i in range(len(df_test.id)):\n",
    "    submission.write(str(df_test.id[i])+\",\"+str(smote_pred_test[i])+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TareafinalML ACt2",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
